{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01e9cc8-6c63-42e1-8227-893f5757df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -mkdir /readme_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f440c26b-e793-49c5-8a39-b9f83693c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -put README.md /readme_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e812e1f1-9f9e-41df-8ceb-8c028647702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8 K  5.4 K  /readme_test/README.md\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -du -h /readme_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7c6f9c-b047-4b85-901e-a03651038edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   3 root supergroup       1840 2023-12-02 23:54 /readme_test/README.md\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /readme_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f25ad92-6915-4889-a7d3-02780b7886c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-cat: Not enough arguments: expected 1 but got 0\n",
      "Usage: hadoop fs [generic options]\n",
      "\t[-appendToFile [-n] <localsrc> ... <dst>]\n",
      "\t[-cat [-ignoreCrc] <src> ...]\n",
      "\t[-checksum [-v] <src> ...]\n",
      "\t[-chgrp [-R] GROUP PATH...]\n",
      "\t[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]\n",
      "\t[-chown [-R] [OWNER][:[GROUP]] PATH...]\n",
      "\t[-concat <target path> <src path> <src path> ...]\n",
      "\t[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] [-q <thread pool queue size>] <localsrc> ... <dst>]\n",
      "\t[-copyToLocal [-f] [-p] [-crc] [-ignoreCrc] [-t <thread count>] [-q <thread pool queue size>] <src> ... <localdst>]\n",
      "\t[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] [-s] <path> ...]\n",
      "\t[-cp [-f] [-p | -p[topax]] [-d] [-t <thread count>] [-q <thread pool queue size>] <src> ... <dst>]\n",
      "\t[-createSnapshot <snapshotDir> [<snapshotName>]]\n",
      "\t[-deleteSnapshot <snapshotDir> <snapshotName>]\n",
      "\t[-df [-h] [<path> ...]]\n",
      "\t[-du [-s] [-h] [-v] [-x] <path> ...]\n",
      "\t[-expunge [-immediate] [-fs <path>]]\n",
      "\t[-find <path> ... <expression> ...]\n",
      "\t[-get [-f] [-p] [-crc] [-ignoreCrc] [-t <thread count>] [-q <thread pool queue size>] <src> ... <localdst>]\n",
      "\t[-getfacl [-R] <path>]\n",
      "\t[-getfattr [-R] {-n name | -d} [-e en] <path>]\n",
      "\t[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]\n",
      "\t[-head <file>]\n",
      "\t[-help [cmd ...]]\n",
      "\t[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]\n",
      "\t[-mkdir [-p] <path> ...]\n",
      "\t[-moveFromLocal [-f] [-p] [-l] [-d] <localsrc> ... <dst>]\n",
      "\t[-moveToLocal <src> <localdst>]\n",
      "\t[-mv <src> ... <dst>]\n",
      "\t[-put [-f] [-p] [-l] [-d] [-t <thread count>] [-q <thread pool queue size>] <localsrc> ... <dst>]\n",
      "\t[-renameSnapshot <snapshotDir> <oldName> <newName>]\n",
      "\t[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]\n",
      "\t[-rmdir [--ignore-fail-on-non-empty] <dir> ...]\n",
      "\t[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]\n",
      "\t[-setfattr {-n name [-v value] | -x name} <path>]\n",
      "\t[-setrep [-R] [-w] <rep> <path> ...]\n",
      "\t[-stat [format] <path> ...]\n",
      "\t[-tail [-f] [-s <sleep interval>] <file>]\n",
      "\t[-test -[defswrz] <path>]\n",
      "\t[-text [-ignoreCrc] <src> ...]\n",
      "\t[-touch [-a] [-m] [-t TIMESTAMP (yyyyMMdd:HHmmss) ] [-c] <path> ...]\n",
      "\t[-touchz <path> ...]\n",
      "\t[-truncate [-w] <length> <path> ...]\n",
      "\t[-usage [cmd ...]]\n",
      "\n",
      "Generic options supported are:\n",
      "-conf <configuration file>        specify an application configuration file\n",
      "-D <property=value>               define a value for a given property\n",
      "-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\n",
      "-jt <local|resourcemanager:port>  specify a ResourceManager\n",
      "-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster\n",
      "-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath\n",
      "-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines\n",
      "\n",
      "The general command line syntax is:\n",
      "command [genericOptions] [commandOptions]\n",
      "\n",
      "Usage: hadoop fs [generic options] -cat [-ignoreCrc] <src> ...\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e1c4db-370a-4fd5-81b0-1115397f98a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Maps  = 15\n",
      "Samples per Map = 1800\n",
      "Wrote input for Map #0\n",
      "Wrote input for Map #1\n",
      "Wrote input for Map #2\n",
      "Wrote input for Map #3\n",
      "Wrote input for Map #4\n",
      "Wrote input for Map #5\n",
      "Wrote input for Map #6\n",
      "Wrote input for Map #7\n",
      "Wrote input for Map #8\n",
      "Wrote input for Map #9\n",
      "Wrote input for Map #10\n",
      "Wrote input for Map #11\n",
      "Wrote input for Map #12\n",
      "Wrote input for Map #13\n",
      "Wrote input for Map #14\n",
      "Starting Job\n",
      "2023-12-03 22:20:37 INFO  DefaultNoHARMFailoverProxyProvider:64 - Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "2023-12-03 22:20:38 INFO  JobResourceUploader:907 - Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1701630638891_0001\n",
      "2023-12-03 22:20:38 INFO  FileInputFormat:300 - Total input files to process : 15\n",
      "2023-12-03 22:20:38 INFO  JobSubmitter:202 - number of splits:15\n",
      "2023-12-03 22:20:39 INFO  JobSubmitter:298 - Submitting tokens for job: job_1701630638891_0001\n",
      "2023-12-03 22:20:39 INFO  JobSubmitter:299 - Executing with tokens: []\n",
      "2023-12-03 22:20:39 INFO  Configuration:2854 - resource-types.xml not found\n",
      "2023-12-03 22:20:39 INFO  ResourceUtils:476 - Unable to find 'resource-types.xml'.\n",
      "2023-12-03 22:20:40 INFO  YarnClientImpl:338 - Submitted application application_1701630638891_0001\n",
      "2023-12-03 22:20:40 INFO  Job:1682 - The url to track the job: http://resourcemanager:8088/proxy/application_1701630638891_0001/\n",
      "2023-12-03 22:20:40 INFO  Job:1727 - Running job: job_1701630638891_0001\n",
      "2023-12-03 22:20:58 INFO  Job:1748 - Job job_1701630638891_0001 running in uber mode : false\n",
      "2023-12-03 22:20:58 INFO  Job:1755 -  map 0% reduce 0%\n",
      "2023-12-03 22:21:07 INFO  Job:1755 -  map 13% reduce 0%\n",
      "2023-12-03 22:21:08 INFO  Job:1755 -  map 20% reduce 0%\n",
      "2023-12-03 22:21:13 INFO  Job:1755 -  map 27% reduce 0%\n",
      "2023-12-03 22:21:14 INFO  Job:1755 -  map 33% reduce 0%\n",
      "2023-12-03 22:21:15 INFO  Job:1755 -  map 40% reduce 0%\n",
      "2023-12-03 22:21:20 INFO  Job:1755 -  map 47% reduce 0%\n",
      "2023-12-03 22:21:21 INFO  Job:1755 -  map 53% reduce 0%\n",
      "2023-12-03 22:21:22 INFO  Job:1755 -  map 60% reduce 0%\n",
      "2023-12-03 22:21:28 INFO  Job:1755 -  map 73% reduce 0%\n",
      "2023-12-03 22:21:34 INFO  Job:1755 -  map 80% reduce 0%\n",
      "2023-12-03 22:21:35 INFO  Job:1755 -  map 87% reduce 0%\n",
      "2023-12-03 22:21:37 INFO  Job:1755 -  map 87% reduce 29%\n",
      "2023-12-03 22:21:41 INFO  Job:1755 -  map 93% reduce 29%\n",
      "2023-12-03 22:21:42 INFO  Job:1755 -  map 100% reduce 29%\n",
      "2023-12-03 22:21:43 INFO  Job:1755 -  map 100% reduce 31%\n",
      "2023-12-03 22:21:44 INFO  Job:1755 -  map 100% reduce 100%\n",
      "2023-12-03 22:21:44 INFO  Job:1766 - Job job_1701630638891_0001 completed successfully\n",
      "2023-12-03 22:21:45 INFO  Job:1773 - Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=336\n",
      "\t\tFILE: Number of bytes written=4461026\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3875\n",
      "\t\tHDFS: Number of bytes written=215\n",
      "\t\tHDFS: Number of read operations=65\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=3\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=15\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=15\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=153926\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=46636\n",
      "\t\tTotal time spent by all map tasks (ms)=76963\n",
      "\t\tTotal time spent by all reduce tasks (ms)=23318\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=76963\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=23318\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=78810112\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=23877632\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=15\n",
      "\t\tMap output records=30\n",
      "\t\tMap output bytes=270\n",
      "\t\tMap output materialized bytes=420\n",
      "\t\tInput split bytes=2105\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=420\n",
      "\t\tReduce input records=30\n",
      "\t\tReduce output records=0\n",
      "\t\tSpilled Records=60\n",
      "\t\tShuffled Maps =15\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=15\n",
      "\t\tGC time elapsed (ms)=728\n",
      "\t\tCPU time spent (ms)=7080\n",
      "\t\tPhysical memory (bytes) snapshot=4348375040\n",
      "\t\tVirtual memory (bytes) snapshot=40969293824\n",
      "\t\tTotal committed heap usage (bytes)=3541565440\n",
      "\t\tPeak Map Physical memory (bytes)=287158272\n",
      "\t\tPeak Map Virtual memory (bytes)=2562977792\n",
      "\t\tPeak Reduce Physical memory (bytes)=233349120\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2565697536\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1770\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=97\n",
      "Job Finished in 67.8 seconds\n",
      "Estimated value of Pi is 3.14162962962962962963\n"
     ]
    }
   ],
   "source": [
    "!hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar pi 15 1800\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf56cb-6d63-4774-8a19-dc179a636a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
