{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01e9cc8-6c63-42e1-8227-893f5757df17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56.65s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mrjob in /usr/local/lib/python3.10/dist-packages (0.7.4)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from mrjob) (6.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63.47s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pyarrow 14.0.1\n",
      "Uninstalling pyarrow-14.0.1:\n",
      "  Successfully uninstalled pyarrow-14.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69.55s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Using cached pyarrow-14.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.26.2)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-14.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78.22s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84.83s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.2)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install mrjob\n",
    "! pip uninstall pyarrow -y\n",
    "! pip install pyarrow\n",
    "! pip install pandas\n",
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f440c26b-e793-49c5-8a39-b9f83693c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CLASSPATH'] = '/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/common/hadoop-registry-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.6.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-commons-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-tree-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.6.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e812e1f1-9f9e-41df-8ceb-8c028647702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarrow import fs\n",
    "hdfs = fs.HadoopFileSystem(\"namenode\", 8020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7c6f9c-b047-4b85-901e-a03651038edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.create_dir('/homework_2_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5acf56cb-6d63-4774-8a19-dc179a636a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SW_EpisodeVI.txt', 'rb') as f:\n",
    "    text = f.read()\n",
    "with hdfs.open_output_stream(\"/homework_2_2/SW_EpisodeVI.txt\") as file:\n",
    "   file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7100977-1a28-4190-a4b7-bcfc718a4597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting longest_sentence.py\n"
     ]
    }
   ],
   "source": [
    "%%file longest_sentence.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRLongestSentencePerCharacter(MRJob):\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_get_sentences,\n",
    "                   reducer=self.reducer_find_longest_sentence),\n",
    "            MRStep(reducer=self.reducer_final)\n",
    "        ]\n",
    "\n",
    "    def mapper_get_sentences(self, _, line):\n",
    "        # yield each word in the line\n",
    "        dialogue = line.split('\" \"')\n",
    "        yield dialogue[1], dialogue[-1].replace(\"\\\"\", '')\n",
    "\n",
    "    def reducer_find_longest_sentence(self, character, sentences):\n",
    "        yield None, (max(sentences, key=len), character)\n",
    "\n",
    "    def reducer_final(self, _, word_count_pairs):\n",
    "        # sorted_sentences = sorted(word_count_pairs, reverse=True)\n",
    "        sorted_sentences = sorted(word_count_pairs, key=lambda x: len(x[0]), reverse=True)\n",
    "        for sentence, character in sorted_sentences:\n",
    "            yield character, sentence\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRLongestSentencePerCharacter.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b495e-2a6d-4766-bff5-f7be7221b082",
   "metadata": {},
   "source": [
    "# EPISODE IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03d0a069-d339-4597-b813-c9b0c7392d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4985.04s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/longest_sentence.root.20231204.093859.802121\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/longest_sentence.root.20231204.093859.802121/output\n",
      "Streaming final output from /tmp/longest_sentence.root.20231204.093859.802121/output...\n",
      "Removing temp directory /tmp/longest_sentence.root.20231204.093859.802121...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4990.51s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 3.3.6\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\n",
      "Creating temp directory /tmp/longest_sentence.root.20231204.093905.306696\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.093905.306696/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.093905.306696/files/\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar3321695638890832002/] [] /tmp/streamjob7847097324245092753.jar tmpDir=null\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1701677628324_0001\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1701677628324_0001\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1701677628324_0001\n",
      "  The url to track the job: http://resourcemanager:8088/proxy/application_1701677628324_0001/\n",
      "  Running job: job_1701677628324_0001\n",
      "  Job job_1701677628324_0001 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1701677628324_0001 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.093905.306696/step-output/0000\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=82374\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=9096\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=74581\n",
      "\t\tFILE: Number of bytes written=997750\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=82578\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=9096\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10833920\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=6576128\n",
      "\t\tTotal time spent by all map tasks (ms)=10580\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=21160\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6422\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=12844\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10580\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6422\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2090\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=123\n",
      "\t\tInput split bytes=204\n",
      "\t\tMap input records=1011\n",
      "\t\tMap output bytes=72432\n",
      "\t\tMap output materialized bytes=74587\n",
      "\t\tMap output records=1011\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=273797120\n",
      "\t\tPeak Map Virtual memory (bytes)=2562555904\n",
      "\t\tPeak Reduce Physical memory (bytes)=174018560\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2567610368\n",
      "\t\tPhysical memory (bytes) snapshot=720396288\n",
      "\t\tReduce input groups=61\n",
      "\t\tReduce input records=1011\n",
      "\t\tReduce output records=61\n",
      "\t\tReduce shuffle bytes=74587\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=2022\n",
      "\t\tTotal committed heap usage (bytes)=555220992\n",
      "\t\tVirtual memory (bytes) snapshot=7691784192\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar8665283165736487396/] [] /tmp/streamjob8237486004771932005.jar tmpDir=null\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1701677628324_0002\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1701677628324_0002\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1701677628324_0002\n",
      "  The url to track the job: http://resourcemanager:8088/proxy/application_1701677628324_0002/\n",
      "  Running job: job_1701677628324_0002\n",
      "  Job job_1701677628324_0002 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1701677628324_0002 completed successfully\n",
      "  Output directory: hdfs:///homework_2_2/SW_EpisodeIV_longest\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=13192\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=8608\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=9288\n",
      "\t\tFILE: Number of bytes written=866876\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=13512\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=8608\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10761216\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=5779456\n",
      "\t\tTotal time spent by all map tasks (ms)=10509\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=21018\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5644\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=11288\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10509\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5644\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1870\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=135\n",
      "\t\tInput split bytes=320\n",
      "\t\tMap input records=61\n",
      "\t\tMap output bytes=9128\n",
      "\t\tMap output materialized bytes=9294\n",
      "\t\tMap output records=61\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=271081472\n",
      "\t\tPeak Map Virtual memory (bytes)=2562400256\n",
      "\t\tPeak Reduce Physical memory (bytes)=179617792\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2565894144\n",
      "\t\tPhysical memory (bytes) snapshot=721104896\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce input records=61\n",
      "\t\tReduce output records=61\n",
      "\t\tReduce shuffle bytes=9294\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=122\n",
      "\t\tTotal committed heap usage (bytes)=580386816\n",
      "\t\tVirtual memory (bytes) snapshot=7689662464\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///homework_2_2/SW_EpisodeIV_longest\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.093905.306696...\n",
      "Removing temp directory /tmp/longest_sentence.root.20231204.093905.306696...\n"
     ]
    }
   ],
   "source": [
    "!python3 longest_sentence.py SW_EpisodeIV.txt > SW_EpisodeIV_longest.txt\n",
    "!python3 longest_sentence.py -r hadoop hdfs://namenode:8020/homework_2_2/SW_EpisodeIV.txt --output /homework_2_2/SW_EpisodeIV_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "59d374c4-c938-4d00-9caa-cd5619d064fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5183.21s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"LEIA\"\t\"General Kenobi, years ago you served my father in the Clone Wars.  Now he begs you to help him in his struggle against the Empire.  I regret that I am unable to present my father's request to you in person, but my ship has fallen under attack and I'm afraid my mission to bring you to Alderaan has failed.  I have placed information vital to the survival of the Rebellion into the memory systems of this R2 unit.  My father will know how to retrieve it.  You must see this droid safely delivered to him on Alderaan.  This is our most desperate hour.  Help me, Obi-Wan Kenobi, you're my only hope.\"\n",
      "\"BIGGS\"\t\"I feel for you, Luke, you're going to have to learn what seems to be important or what really is important.  What good is all your uncle's work if it's taken over by the Empire?...  You know they're starting to nationalize commerce in the central systems...it won't be long before your uncle is merely a tenant, slaving for the greater glory of the Empire.\"\n",
      "\"DODONNA\"\t\"The approach will not be easy.  You are required to maneuver straight down this trench and skim the surface to this point.  The target area is only two meters wide.  It's a small thermal exhaust port, right below the main port.  The shaft leads directly to the reactor system.  A precise hit will start a chain reaction which should destroy the station.\"\n",
      "\"JABBA\"\t\"Put your blasters away.  Han, my boy, I'm only doing this because you're the best and I need you.  So, for an extra, say... twenty percent I'll give you a little more time... but this is it.  If you disappoint me again, I'll put a price on your head so large you won't be able to go near a civilized system for the rest of your short life.\"\n",
      "\"LUKE\"\t\"... so I cut off my power, shut down the afterburners and came in low on Deak's trail.  I was so close I thought I was going to fry my instruments. As it was I busted up the Skyhopper pretty bad.  Uncle Owen was pretty upset.  He grounded me for the rest of the season.  You should have been there... it was fantastic.\"\n",
      "\"TARKIN\"\t\"Not after we demonstrate the power of this station.  In a way, you have determined the choice of the planet that'll be destroyed first.  Since you are reluctant to provide us with the location of the Rebel base, I have chosen to test this station's destructive power... on your home planet of Alderaan.\"\n",
      "\"THREEPIO\"\t\"He says he's the property of Obi-Wan Kenobi, a resident of these parts.  And it's a private message for him.  Quite frankly, sir, I don't know what he's talking about.  Our last master was Captain Antilles, but with what we've been through, this little R2 unit has become a bit eccentric.\"\n",
      "\"BEN\"\t\"A young Jedi named Darth Vader, who was a pupil of mine until he turned to evil, helped the Empire hunt down and destroy the Jedi Knights.  He betrayed and murdered your father.  Now the Jedi are all but extinct.  Vader was seduced by the dark side of the Force.\"\n",
      "\"VADER\"\t\"Don't play games with me, Your Highness.  You weren't on any mercy mission this time.  You passed directly through a restricted system.  Several transmissions were beamed to this ship by Rebel spies.  I want to know what happened to the plans they sent you.\"\n",
      "\"HAN\"\t\"Kid, I've flown from one side of this galaxy to the other.  I've seen a lot of strange stuff, but I've never seen anything to make me believe there's one all-powerful force controlling everything.  There's no mystical energy field that controls my destiny.\"\n",
      "\"MOTTI\"\t\"Don't try to frighten us with your sorcerer's ways, Lord Vader.  Your sad devotion to that ancient religion has not helped you conjure up the stolen data tapes, or given you clairvoyance enough to find the Rebel's hidden fort...\"\n",
      "\"OFFICER CASS\"\t\"Our scout ships have reached Dantooine.  They found the remains of a Rebel base, but they estimate that it has been deserted for some time.  They are now conducting an extensive search of the surrounding systems.\"\n",
      "\"GREEDO\"\t\"It's too late.  You should have paid him when you had the chance.  Jabba's put a price on your head, so large that every bounty hunter in the galaxy will be looking for you.  I'm lucky I found you first.\"\n",
      "\"OWEN\"\t\"Harvest is when I need you the most.  Only one more season.  This year we'll make enough on the harvest so I'll be able to hire some more hands.  And then you can go to the Academy next year.\"\n",
      "\"TAGGE\"\t\"And what of the Rebellion?  If the Rebels have obtained a complete technical readout of this station, it is possible, however unlikely, that they might find a weakness and exploit it.\"\n",
      "\"SECOND OFFICER\"\t\"Lord Vader, the battle station plans are not aboard this ship!  And no transmissions were made.  An escape pod was jettisoned during the fighting, but no life forms were aboard.\"\n",
      "\"FIXER\"\t\"I keep telling you, the Rebellion is a long way from here.  I doubt if the Empire would even fight to keep this system.  Believe me Luke, this planet is a big hunk of nothing...\"\n",
      "\"OFFICER\"\t\"There's no one on board, sir.  According to the log, the crew abandoned ship right after takeoff.  It must be a decoy, sir.  Several of the escape pods have been jettisoned.\"\n",
      "\"RED LEADER\"\t\"I met your father once when I was just a boy.  He was a great pilot.  You'll do all right.  If you've got half of your father's skill, you'll do better than all right.\"\n",
      "\"VOICE\"\t\"We've captured a freighter entering the remains of the Alderaan system.  It's markings match those of a ship that blasted its way out of Mos Eisley.\"\n",
      "\"DEATH STAR INTERCOM VOICE\"\t\"We are approaching the planet Yavin.  The Rebel base is on a moon on the far side.  We are preparing to orbit the planet.\"\n",
      "\"COMMANDER\"\t\"Holding her is dangerous.  If word of this gets out, it could generate sympathy for the Rebellion in the senate.\"\n",
      "\"HUMAN\"\t\"Don't insult us.  You just watch yourself.  We're wanted men.  I have the death sentence on twelve systems.\"\n",
      "\"TROOPER\"\t\"The ship's all yours.  If the scanners pick up anything, report it immediately.  All right, let's go.\"\n",
      "\"WEDGE\"\t\"My scope shows the tower, but I can't see the exhaust port!  Are you sure the computer can hit it?\"\n",
      "\"REBEL OFFICER\"\t\"We intercepted no transmissions. Aaah...  This is a consular ship. Were on a diplomatic mission.\"\n",
      "\"ASTRO-OFFICER\"\t\"We count thirty Rebel ships, Lord Vader.  But they're so small they're evading our turbo-lasers!\"\n",
      "\"AUNT BERU\"\t\"Owen, he can't stay here forever.  Most of his friends have gone.  It means so much to him.\"\n",
      "\"WILLARD\"\t\"When we heard about Alderaan, we were afraid that you were... lost along with your father.\"\n",
      "\"MASSASSI INTERCOM VOICE\"\t\"Stand-by alert.  Death Star approaching.  Estimated time to firing range, fifteen minutes.\"\n",
      "\"IMPERIAL OFFICER\"\t\"The final check-out is complete.  All systems are operational.  What course shall we set?\"\n",
      "\"CONTROL OFFICER\"\t\"Squad leaders, we've picked up a new group of signals.  Enemy fighters coming your way.\"\n",
      "\"GOLD LEADER\"\t\"Pardon me for asking, sir, but what good are snub fighters going to be against that?\"\n",
      "\"BASE VOICE\"\t\"His computer's off.  Luke, you switched off your targeting computer.  What's wrong?\"\n",
      "\"INTERCOM VOICE\"\t\"Governor Tarkin, we have an emergency alert in detention block AA-twenty-three.\"\n",
      "\"GANTRY OFFICER\"\t\"TX-four-one-two.  Why aren't you at your post?  TX-four-one-two, do you copy? \"\n",
      "\"CAPTAIN\"\t\"Hold your fire.  There are no life forms.  It must have been short-circuited.\"\n",
      "\"MAN\"\t\"All flight troops, man your stations.  All flight troops, man your stations.\"\n",
      "\"BERU\"\t\"Luke, tell Owen that if he gets a translator to be sure it speaks Bocce.\"\n",
      "\"GOLD FIVE\"\t\"I'd say about twenty guns.  Some on the surface, some on the towers.\"\n",
      "\"BARTENDER\"\t\"Your droids. They'll have to wait outside.  We don't want them here.\"\n",
      "\"VOICE OVER DEATH STAR INTERCOM\"\t\"Clear Bay twenty-three-seven.  We are opening the magnetic field.\"\n",
      "\"CHIEF\"\t\"This R2 unit of your seems a bit beat up.  Do you want a new one?\"\n",
      "\"RED TEN\"\t\"There's a heavy fire zone on this side. Red Five, where are you?\"\n",
      "\"FIRST TROOPER\"\t\"Someone was in the pod.  The tracks go off in this direction. \"\n",
      "\"CAMIE\"\t\"It was just Wormie on another rampage.\"\n",
      "\"GOLD TWO\"\t\"Computer's locked.  Getting a signal.\"\n",
      "\"TECHNICIAN\"\t\"We'll get to work on him right away.\"\n",
      "\"WOMAN\"\t\"I've told you kids to slow down!\"\n",
      "\"FIRST OFFICER\"\t\"Follow me!  You stand guard.\"\n",
      "\"CREATURE\"\t\"Negola dewaghi wooldugger?!?\"\n",
      "\"SECOND TROOPER\"\t\"Maybe it's another drill.\"\n",
      "\"RED ELEVEN\"\t\"Red Eleven standing by.\"\n",
      "\"CHIEF PILOT\"\t\"There goes another one.\"\n",
      "\"RED SEVEN\"\t\"Red Seven standing by.\"\n",
      "\"DEAK\"\t\"Not again!  Forget it.\"\n",
      "\"RED NINE\"\t\"Red Nine standing by.\"\n",
      "\"PORKINS\"\t\"Red Six standing by.\"\n",
      "\"TROOPER VOICE\"\t\"Open up in there!\"\n",
      "\"WINGMAN\"\t\"Yes, sir.\"\n",
      "\"dialogue\\\"\"\t\"dialogue\"\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat /homework_2_2/SW_EpisodeIV_longest/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea1aa7-38aa-40dd-b072-82f2cc2aeee1",
   "metadata": {},
   "source": [
    "# EPISODE V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "af111028-a9ae-4cde-9667-11df165428a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7500.43s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/longest_sentence.root.20231204.102055.196015\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/longest_sentence.root.20231204.102055.196015/output\n",
      "Streaming final output from /tmp/longest_sentence.root.20231204.102055.196015/output...\n",
      "Removing temp directory /tmp/longest_sentence.root.20231204.102055.196015...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7505.90s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 3.3.6\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\n",
      "Creating temp directory /tmp/longest_sentence.root.20231204.102100.674637\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.102100.674637/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.102100.674637/files/\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar7501557000497947898/] [] /tmp/streamjob7191992335175476853.jar tmpDir=null\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1701677628324_0012\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1701677628324_0012\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1701677628324_0012\n",
      "  The url to track the job: http://resourcemanager:8088/proxy/application_1701677628324_0012/\n",
      "  Running job: job_1701677628324_0012\n",
      "  Job job_1701677628324_0012 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1701677628324_0012 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.102100.674637/step-output/0000\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=59560\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=5573\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=52329\n",
      "\t\tFILE: Number of bytes written=953243\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=59762\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=5573\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12589056\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=6212608\n",
      "\t\tTotal time spent by all map tasks (ms)=12294\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=24588\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6067\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=12134\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=12294\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6067\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2630\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=225\n",
      "\t\tInput split bytes=202\n",
      "\t\tMap input records=839\n",
      "\t\tMap output bytes=50590\n",
      "\t\tMap output materialized bytes=52335\n",
      "\t\tMap output records=839\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=295862272\n",
      "\t\tPeak Map Virtual memory (bytes)=2562002944\n",
      "\t\tPeak Reduce Physical memory (bytes)=177766400\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2566668288\n",
      "\t\tPhysical memory (bytes) snapshot=745385984\n",
      "\t\tReduce input groups=49\n",
      "\t\tReduce input records=839\n",
      "\t\tReduce output records=49\n",
      "\t\tReduce shuffle bytes=52335\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1678\n",
      "\t\tTotal committed heap usage (bytes)=592969728\n",
      "\t\tVirtual memory (bytes) snapshot=7690280960\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar3955093454962426903/] [] /tmp/streamjob7852095790405664316.jar tmpDir=null\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1701677628324_0013\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1701677628324_0013\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1701677628324_0013\n",
      "  The url to track the job: http://resourcemanager:8088/proxy/application_1701677628324_0013/\n",
      "  Running job: job_1701677628324_0013\n",
      "  Job job_1701677628324_0013 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1701677628324_0013 completed successfully\n",
      "  Output directory: hdfs:///homework_2_2/SW_EpisodeV_longest\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=8360\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=5181\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5712\n",
      "\t\tFILE: Number of bytes written=859721\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=8680\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=5181\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=14031872\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=6483968\n",
      "\t\tTotal time spent by all map tasks (ms)=13703\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=27406\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6332\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=12664\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=13703\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6332\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2450\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=177\n",
      "\t\tInput split bytes=320\n",
      "\t\tMap input records=49\n",
      "\t\tMap output bytes=5590\n",
      "\t\tMap output materialized bytes=5718\n",
      "\t\tMap output records=49\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=270770176\n",
      "\t\tPeak Map Virtual memory (bytes)=2562502656\n",
      "\t\tPeak Reduce Physical memory (bytes)=190713856\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2567360512\n",
      "\t\tPhysical memory (bytes) snapshot=729530368\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce input records=49\n",
      "\t\tReduce output records=49\n",
      "\t\tReduce shuffle bytes=5718\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=98\n",
      "\t\tTotal committed heap usage (bytes)=597688320\n",
      "\t\tVirtual memory (bytes) snapshot=7692320768\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///homework_2_2/SW_EpisodeV_longest\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.102100.674637...\n",
      "Removing temp directory /tmp/longest_sentence.root.20231204.102100.674637...\n"
     ]
    }
   ],
   "source": [
    "!python3 longest_sentence.py SW_EpisodeV.txt > SW_EpisodeV_longest.txt\n",
    "!python3 longest_sentence.py -r hadoop hdfs://namenode:8020/homework_2_2/SW_EpisodeV.txt --output /homework_2_2/SW_EpisodeV_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d7d2f6f2-d351-4d94-a63d-fe05c01c45ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7633.42s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"YODA\"\t\"Ready, are you? What know you of ready? For eight hundred years  have I trained Jedi. My own counsel will I keep on who is to be trained! A Jedi must have the deepest commitment, the most serious mind.  This one a long time have I watched. Never his mind on where he was. Hmm? What he was doing. Hmph. Adventure. Heh! Excitement. Heh! A Jedi craves not these things.  You are reckless!\"\n",
      "\"VADER\"\t\"There is no escape. Don't make me destroy you. You do not yet  realize your importance. You have only begun to discover you power. Join me and I will complete your training. With our combined strength, we can end this destructive conflict and bring order to the galaxy.\"\n",
      "\"LEIA\"\t\"All troop carriers will assemble at the north entrance. The  heavy transport ships will leave as soon as they're loaded. Only two fighter escorts per ship. The energy shield can only be opened for a short time, so you'll have to stay very close to your transports.\"\n",
      "\"THREEPIO\"\t\"Don't try to blame me. I didn't ask you to turn on the  thermal heater. I merely commented that it was freezing in the princess's chamber. But it's supposed to be freezing. How are we going to dry out all her clothes? I really don't know.\"\n",
      "\"LANDO\"\t\"That's always been a danger looming like a shadow over  everything we've built here. But things have developed that will insure security. I've just made a deal that will keep the Empire out of here forever.\"\n",
      "\"VEERS\"\t\"My lord, the fleet has moves out of light-speed. Com-Scan has  detected an energy field protecting an area around the sixth planet of the Hoth system. The field is strong enough to deflect any bombardment.\"\n",
      "\"LUKE\"\t\"If you're saying coming here was a bad idea, I'm beginning to  agree with you. Oh, Artoo, what are we doing here? It's like... something out of a dream, or, I don't know. Maybe I'm just going crazy.\"\n",
      "\"PIETT\"\t\"Lord Vader, our ships have completed their scan of the area and  found nothing. If the Millennium Falcon went into light-speed, it'll be on the other side of the galaxy by now.\"\n",
      "\"NEEDA\"\t\"...and that, Lord Vader, was the last time they  appeared in any of our scopes. Considering the amount of damage we've sustained, they must have been destroyed.\"\n",
      "\"REBEL CAPTAIN\"\t\"Groups seven and ten will stay behind to fly the  speeders. As soon as each transport is loaded, evacuation control will give clearance for immediate launch.\"\n",
      "\"HAN\"\t\"Yeah, that's what I thought. Mynock. Chewie, check the rest of  the ship, make sure there aren't any more attached. They're chewing on the power cables.\"\n",
      "\"RIEEKAN\"\t\"Reroute all power to the energy shield. We've got to hold  them till all transports are away. Prepare for ground assault.\"\n",
      "\"ZEV\"\t\"This is Rouge Two. this is Rouge Two. Captain  Solo, so you copy? Commander Skywalker, do you copy? This is Rouge Two.\"\n",
      "\"BEN\"\t\"But you cannot control it. This is a dangerous time for you, when  you will be tempted by the dark side of the Force.\"\n",
      "\"CREATURE\"\t\"Not far. Yoda not far. Patience. Soon you will be with him.   Rootleaf, I cook. Why wish you become Jedi? Hm?\"\n",
      "\"DECK OFFICER\"\t\"Sir, Commander Skywalker hasn't come in through the  south entrance. He might have forgotten to check in.\"\n",
      "\"OZZEL\"\t\"My lord, there are so many uncharted settlements. It could be  smugglers, it could be...\"\n",
      "\"DERLIN\"\t\"Your Highness, there's nothing more we can do tonight. The  shield doors must be closed.\"\n",
      "\"CONTROLLER\"\t\"General, there's a fleet of Star Destroyers coming out of  hyperspace in sector four.\"\n",
      "\"DACK\"\t\"Luke, we've got a malfunction in fire control. I'll have to cut  in the auxiliary.\"\n",
      "\"LIEUTENANT\"\t\"Sir, all the patrols are in. There's still no contact from  Skywalker or Solo.\"\n",
      "\"EMPEROR\"\t\"The Force is strong with him. The son of Skywalker must not  become a Jedi.\"\n",
      "\"SECOND CONTROLLER\"\t\"Sir, we have a priority signal from the Star  Destroyer Avenger.\"\n",
      "\"MEDICAL DROID\"\t\"Sir, it will take quite awhile to evacuate the T-forty-  sevens.\"\n",
      "\"ASSISTANT OFFICER\"\t\"I'll cover sector twelve. Have com-control set  screen alpha.\"\n",
      "\"TRACKING OFFICER\"\t\"Captain Needa, the ship no longer appears on our  scopes.\"\n",
      "\"SENIOR CONTROLLER\"\t\"No. Wait -- there's something very weak coming  through.\"\n",
      "\"INTERCOM VOICE\"\t\"Permission granted to land on Platform  Three-two-seven.\"\n",
      "\"COMMUNICATIONS OFFICER\"\t\"Captain, Lord Vader demands an update on the  pursuit.\"\n",
      "\"BOBA FETT\"\t\"What if he doesn't survive? He's worth a lot to me.\"\n",
      "\"ANNOUNCER\"\t\"Headquarters personnel, report to command  center.\"\n",
      "\"WEDGE\"\t\"Good luck, Luke. See you at the rendezvous.\"\n",
      "\"IMPERIAL SOLDIER\"\t\"Lord Vader, ship approaching. X-wing class.\"\n",
      "\"HOBBIE\"\t\"Two fighters against a Star Destroyer?\"\n",
      "\"IMPERIAL OFFICER\"\t\"Skywalker has just landed, my lord.\"\n",
      "\"HEAD CONTROLLER\"\t\"K-one-zero...all troops disengage.\"\n",
      "\"TRENCH OFFICER\"\t\"We have spotted Imperial walkers!\"\n",
      "\"CAPTAIN\"\t\"Good. Our first catch of the day.\"\n",
      "\"WOMAN CONTROLLER\"\t\"Stand by, ion control....Fire!\"\n",
      "\"PILOT\"\t\"One-seven, decimal two-eight.\"\n",
      "\"JANSON\"\t\"Coming around. Once more.\"\n",
      "\"STRANGE VOICE\"\t\"Feel like what?\"\n",
      "\"OFFICER\"\t\"Begin retreat!\"\n",
      "\"PILOTS\"\t\"Right. Okay.\"\n",
      "\"MAN\"\t\"Who are you?\"\n",
      "\"REBEL FIGHTER\"\t\"Right, sir.\"\n",
      "\"SECOND OFFICER\"\t\"Fall back!\"\n",
      "\"SECOND THREEPIO\"\t\"E chu ta!\"\n",
      "\"FIRST CONTROLLER\"\t\"Yes, sir.\"\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat /homework_2_2/SW_EpisodeV_longest/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9753d-d595-406c-aa2b-3ca19472fea5",
   "metadata": {},
   "source": [
    "# VI EPISODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "09d77164-d421-4cc2-b581-088454f02016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7643.12s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/longest_sentence.root.20231204.102317.928593\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/longest_sentence.root.20231204.102317.928593/output\n",
      "Streaming final output from /tmp/longest_sentence.root.20231204.102317.928593/output...\n",
      "Removing temp directory /tmp/longest_sentence.root.20231204.102317.928593...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7648.65s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 3.3.6\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\n",
      "Creating temp directory /tmp/longest_sentence.root.20231204.102323.415540\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.102323.415540/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.102323.415540/files/\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar7111838677496797140/] [] /tmp/streamjob8902578759824417991.jar tmpDir=null\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1701677628324_0014\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1701677628324_0014\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1701677628324_0014\n",
      "  The url to track the job: http://resourcemanager:8088/proxy/application_1701677628324_0014/\n",
      "  Running job: job_1701677628324_0014\n",
      "  Job job_1701677628324_0014 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1701677628324_0014 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.102323.415540/step-output/0000\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=52249\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=6991\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=45698\n",
      "\t\tFILE: Number of bytes written=939984\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=52453\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=6991\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12921856\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=6185984\n",
      "\t\tTotal time spent by all map tasks (ms)=12619\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=25238\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6041\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=12082\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=12619\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6041\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2620\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=161\n",
      "\t\tInput split bytes=204\n",
      "\t\tMap input records=674\n",
      "\t\tMap output bytes=44280\n",
      "\t\tMap output materialized bytes=45704\n",
      "\t\tMap output records=674\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=276750336\n",
      "\t\tPeak Map Virtual memory (bytes)=2562973696\n",
      "\t\tPeak Reduce Physical memory (bytes)=174481408\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2569256960\n",
      "\t\tPhysical memory (bytes) snapshot=723148800\n",
      "\t\tReduce input groups=53\n",
      "\t\tReduce input records=674\n",
      "\t\tReduce output records=53\n",
      "\t\tReduce shuffle bytes=45704\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1348\n",
      "\t\tTotal committed heap usage (bytes)=554696704\n",
      "\t\tVirtual memory (bytes) snapshot=7694790656\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar5835079199404358374/] [] /tmp/streamjob1549249395532183076.jar tmpDir=null\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1701677628324_0015\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1701677628324_0015\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1701677628324_0015\n",
      "  The url to track the job: http://resourcemanager:8088/proxy/application_1701677628324_0015/\n",
      "  Running job: job_1701677628324_0015\n",
      "  Job job_1701677628324_0015 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1701677628324_0015 completed successfully\n",
      "  Output directory: hdfs:///homework_2_2/SW_EpisodeVI_longest\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=10487\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=6567\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=7147\n",
      "\t\tFILE: Number of bytes written=862594\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=10807\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=6567\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12199936\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=5726208\n",
      "\t\tTotal time spent by all map tasks (ms)=11914\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=23828\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5592\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=11184\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11914\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5592\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2190\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=158\n",
      "\t\tInput split bytes=320\n",
      "\t\tMap input records=53\n",
      "\t\tMap output bytes=7013\n",
      "\t\tMap output materialized bytes=7153\n",
      "\t\tMap output records=53\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=300564480\n",
      "\t\tPeak Map Virtual memory (bytes)=2562560000\n",
      "\t\tPeak Reduce Physical memory (bytes)=172208128\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2569183232\n",
      "\t\tPhysical memory (bytes) snapshot=762793984\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce input records=53\n",
      "\t\tReduce output records=53\n",
      "\t\tReduce shuffle bytes=7153\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=106\n",
      "\t\tTotal committed heap usage (bytes)=596639744\n",
      "\t\tVirtual memory (bytes) snapshot=7694057472\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///homework_2_2/SW_EpisodeVI_longest\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.102323.415540...\n",
      "Removing temp directory /tmp/longest_sentence.root.20231204.102323.415540...\n"
     ]
    }
   ],
   "source": [
    "!python3 longest_sentence.py SW_EpisodeVI.txt > SW_EpisodeVI_longest.txt\n",
    "!python3 longest_sentence.py -r hadoop hdfs://namenode:8020/homework_2_2/SW_EpisodeVI.txt --output /homework_2_2/SW_EpisodeVI_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ac8abb44-9dc0-4673-b02a-a31222935c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7769.81s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"BEN\"\t\"The Organa household was high-born and politically quite powerful in that system. Leia became a princess by virtue of lineage... no one knew she'd been adopted, of course. But it was a title without real power, since Alderaan had long been a democracy.  Even so, the family continued to be politically powerful, and Leia, following in her foster father's path, became a senator as well.  That's not all she became, of course... she became the leader of her cell in the Alliance against the corrupt Empire. And because she had diplomatic immunity, she was a vital link for getting information to the Rebel cause.  That's what she was doing when her path crossed yours... for her foster parents had always told her to contact me on Tatooine, if her troubles became desperate.\"\n",
      "\"ACKBAR\"\t\"You can see here the Death Star orbiting the forest Moon of Endor. Although the weapon systems on this Death Star are not yet operational, the Death Star does have a strong defense mechanism. It is protected by an energy shield, which is generated from the nearby forest Moon of Endor. The shield must be deactivated if any attack is to be attempted. Once the shield is down, our cruisers will create a perimeter, while the fighters fly into the superstructure and attempt to knock out the main reactor.\"\n",
      "\"LUKE\"\t\"Greetings, Exalted One. Allow me to introduce myself. I am Luke Skywalker, Jedi Knight and friend to Captain Solo. I know that you are powerful, mighty Jabba, and that your anger with Solo must be equally powerful. I seek an audience with Your Greatness to bargain for Solo's life.  With your wisdom, I'm sure that we can work out an arrangement which will be mutually beneficial and enable us to avoid any unpleasant confrontation. As a token of my goodwill, I present to you a gift: these two droids.\"\n",
      "\"MON MOTHMA\"\t\"The data brought to us by the Bothan spies pinpoints the exact location of the Emperor's new battle station. We also know that the weapon systems of this Death Star are not yet operational. With the Imperial Fleet spread throughout the galaxy in a vain effort to engage us, it is relatively unprotected. But most important of all, we've learned that the Emperor himself is personally overseeing the final stages of the construction of this Death Star.\"\n",
      "\"YODA\"\t\"Luke...Luke...Do not...Do not underestimate the powers of the Emperor, or suffer your father's fate, you will. Luke, when gone am I , the last of the Jedi will you be. Luke, the Force runs strong in your family. Pass on what you have learned, Luke...  There is... another...Sky...Sky...walker.\"\n",
      "\"EMPEROR\"\t\"...are walking into a trap. As is your Rebel fleet! It was I who allowed the Alliance to know the location of the shield generator. It is quite safe from your pitiful little band. An entire legion of my best troops awaits them.\"\n",
      "\"VADER\"\t\"Sister! So...you have a twin sister. Your feelings have now betrayed her, too. Obi-Wan was wise to hide her from me. Now his failure is complete. If you will not turn to the dark side, then perhaps she will.\"\n",
      "\"THREEPIO\"\t\"Victims of the almighty Sarlacc: His Excellency hopes that you will die honorably. But should any of you wish to beg for mercy, the great Jabba the Hutt will now listen to your pleas.\"\n",
      "\"GENERAL MADINE\"\t\"We have stolen a small Imperial shuttle. Disguised as a cargo ship, and using a secret Imperial code, a strike team will land on the moon and deactivate the shield generator.\"\n",
      "\"COMMANDER\"\t\"This is a Rebel that surrendered to us. Although he denies it, I believe there may be more of them, and I request permission to conduct a further search of the area.\"\n",
      "\"HAN\"\t\"Now don't get jittery, Luke. There are a lot of command ships. Keep your distance though, Chewie, but don't look like you're trying to keep your distance.\"\n",
      "\"LANDO\"\t\"We've got to be able to get some kind of a reading on that shield, up or down. Well, how could they be jamming us if they don't know if we're coming.\"\n",
      "\"NINEDENINE\"\t\"You're a feisty little one, but you'll soon learn some respect. I have need for you on the master's Sail Barge. And I think you'll fit in nicely.\"\n",
      "\"DEATH STAR CONTROLLER\"\t\"The security deflector shield will be deactivated when we have confirmation of your code transmission. Stand by... You are clear to proceed.\"\n",
      "\"HAN/PILOT\"\t\"It's over, Commander. The Rebels have been routed. They're fleeing into the woods. We need reinforcements to continue the pursuit.\"\n",
      "\"PIETT\"\t\"I have my orders from the Emperor himself. He has something special planned for them. We only need to keep them from escaping.\"\n",
      "\"SHUTTLE CAPTAIN\"\t\"Command station, this is ST 321. Code Clearance Blue. We're starting our approach. Deactivate the security shield.\"\n",
      "\"LEIA\"\t\"No! Luke, run away, far away. If he can feel your presence, then leave this place. I wish I could go with you.\"\n",
      "\"CONTROLLER\"\t\"Shuttle Tydirium, deactivation of the shield will commence immediately. Follow your present course.\"\n",
      "\"JABBA\"\t\"It's too late for that, Solo. You may have been a good smuggler, but now you're Bantha fodder.\"\n",
      "\"ANAKIN\"\t\"You already have, Luke. You were right about me. Tell your sister...you were right.\"\n",
      "\"WEDGE\"\t\"Cut to the left! I'll take the leader! They're heading for the medical frigate.\"\n",
      "\"JERJERROD\"\t\"Lord Vader, this is an unexpected pleasure.  We're honored by your presence.\"\n",
      "\"GUARD\"\t\"Halt! The Emperor does not wish to be disturbed at the moment.\"\n",
      "\"OFFICER\"\t\"Inform the commander that Lord Vader's shuttle has arrived.\"\n",
      "\"BOUSHH\"\t\"Just relax for a moment. You're free of the carbonite.\"\n",
      "\"CONTROL ROOM COMMANDER\"\t\"Send three squads to help. Open the back door.\"\n",
      "\"PILOT VOICE\"\t\"Parts and technical crew for the forest moon.\"\n",
      "\"SCOUT #1\"\t\"Go get your ride and take her back to base.\"\n",
      "\"STORMTROOPER\"\t\"All right, move it! I said move it! Go on!\"\n",
      "\"RED THREE\"\t\"Three of them coming in, twenty degrees!\"\n",
      "\"BIB\"\t\"Nee Jabba no badda. Me chaade su goodie.\"\n",
      "\"OOLA\"\t\"Na Chuba negatorie Na! Na! Natoota...\"\n",
      "\"RED LEADER\"\t\"I get no reading. Are you sure?\"\n",
      "\"SCOUT\"\t\"Look! Over there! Stop him!\"\n",
      "\"BUNKER COMMANDER\"\t\"Bring those two down here!\"\n",
      "\"SCOUT #l\"\t\"Freeze!  Come on, get up!\"\n",
      "\"REBEL PILOT\"\t\"There's too many of them!\"\n",
      "\"GREEN LEADER\"\t\"Green Leader standing by.\"\n",
      "\"GRAY LEADER\"\t\"Gray Leader standing by.\"\n",
      "\"PILOT #2\"\t\"Get him off of there!\"\n",
      "\"STRANGE VOICE\"\t\"Tee chuta hhat yudd!\"\n",
      "\"VOICE\"\t\"I'm with you, too!\"\n",
      "\"PILOT\"\t\"Copy, Gold Leader.\"\n",
      "\"NAVIGATOR\"\t\"Pressure's steady.\"\n",
      "\"LURE\"\t\"But you'll die.\"\n",
      "\"SECOND COMMANDER\"\t\"Yes, sir.\"\n",
      "\"SCOUT #2\"\t\"Yes, sir.\"\n",
      "\"OPERATOR\"\t\"Yes, sir.\"\n",
      "\"Y-WING PILOT\"\t\"I'm hit!\"\n",
      "\"RED TWO\"\t\"Got it!\"\n",
      "\"WALKER PILOT #1\"\t\"Look!\"\n",
      "\"HAN and LUKE\"\t\"Leia!\"\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat /homework_2_2/SW_EpisodeVI_longest/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae6671c-8702-46df-b11d-cfd303143909",
   "metadata": {},
   "source": [
    "# ALL EPISODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e4b53f94-2e84-4ba4-9920-8db29620fb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6460.74s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/longest_sentence.root.20231204.100335.514140\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/longest_sentence.root.20231204.100335.514140/output\n",
      "Streaming final output from /tmp/longest_sentence.root.20231204.100335.514140/output...\n",
      "Removing temp directory /tmp/longest_sentence.root.20231204.100335.514140...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6466.24s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 3.3.6\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\n",
      "Creating temp directory /tmp/longest_sentence.root.20231204.100341.020310\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.100341.020310/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.100341.020310/files/\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar2310762603309564108/] [] /tmp/streamjob646086093081293320.jar tmpDir=null\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1701677628324_0010\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1701677628324_0010\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1701677628324_0010\n",
      "  The url to track the job: http://resourcemanager:8088/proxy/application_1701677628324_0010/\n",
      "  Running job: job_1701677628324_0010\n",
      "  Job job_1701677628324_0010 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1701677628324_0010 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.100341.020310/step-output/0000\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=188491\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=17103\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=172570\n",
      "\t\tFILE: Number of bytes written=1193734\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=188701\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=17103\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12198912\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=5935104\n",
      "\t\tTotal time spent by all map tasks (ms)=11913\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=23826\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5796\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=11592\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11913\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5796\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2640\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=142\n",
      "\t\tInput split bytes=210\n",
      "\t\tMap input records=2523\n",
      "\t\tMap output bytes=167278\n",
      "\t\tMap output materialized bytes=172576\n",
      "\t\tMap output records=2523\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=274051072\n",
      "\t\tPeak Map Virtual memory (bytes)=2562121728\n",
      "\t\tPeak Reduce Physical memory (bytes)=173760512\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2568081408\n",
      "\t\tPhysical memory (bytes) snapshot=715595776\n",
      "\t\tReduce input groups=129\n",
      "\t\tReduce input records=2523\n",
      "\t\tReduce output records=129\n",
      "\t\tReduce shuffle bytes=172576\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=5046\n",
      "\t\tTotal committed heap usage (bytes)=554172416\n",
      "\t\tVirtual memory (bytes) snapshot=7691313152\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar4625856030223626612/] [] /tmp/streamjob3633614119636853448.jar tmpDir=null\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Connecting to ResourceManager at resourcemanager/172.18.0.5:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1701677628324_0011\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1701677628324_0011\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1701677628324_0011\n",
      "  The url to track the job: http://resourcemanager:8088/proxy/application_1701677628324_0011/\n",
      "  Running job: job_1701677628324_0011\n",
      "  Job job_1701677628324_0011 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1701677628324_0011 completed successfully\n",
      "  Output directory: hdfs:///homework_2_2/SW_EpisodeIVVVI_longest\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=21199\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=16071\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17469\n",
      "\t\tFILE: Number of bytes written=883247\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=21519\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=16071\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12913664\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=6469632\n",
      "\t\tTotal time spent by all map tasks (ms)=12611\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=25222\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6318\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=12636\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=12611\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6318\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2550\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=195\n",
      "\t\tInput split bytes=320\n",
      "\t\tMap input records=129\n",
      "\t\tMap output bytes=17154\n",
      "\t\tMap output materialized bytes=17475\n",
      "\t\tMap output records=129\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=295387136\n",
      "\t\tPeak Map Virtual memory (bytes)=2561736704\n",
      "\t\tPeak Reduce Physical memory (bytes)=179998720\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2568601600\n",
      "\t\tPhysical memory (bytes) snapshot=768704512\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce input records=129\n",
      "\t\tReduce output records=129\n",
      "\t\tReduce shuffle bytes=17475\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=258\n",
      "\t\tTotal committed heap usage (bytes)=636485632\n",
      "\t\tVirtual memory (bytes) snapshot=7691694080\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///homework_2_2/SW_EpisodeIVVVI_longest\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/longest_sentence.root.20231204.100341.020310...\n",
      "Removing temp directory /tmp/longest_sentence.root.20231204.100341.020310...\n"
     ]
    }
   ],
   "source": [
    "!python3 longest_sentence.py SW_EpisodeIVVVI.txt > SW_EpisodeIVVVI_longest.txt\n",
    "!python3 longest_sentence.py -r hadoop hdfs://namenode:8020/homework_2_2/SW_EpisodeIVVVI.txt --output /homework_2_2/SW_EpisodeIVVVI_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fa39f218-dad4-40ac-a2fd-675c42ca3dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6912.76s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"BEN\"\t\"The Organa household was high-born and politically quite powerful in that system. Leia became a princess by virtue of lineage... no one knew she'd been adopted, of course. But it was a title without real power, since Alderaan had long been a democracy.  Even so, the family continued to be politically powerful, and Leia, following in her foster father's path, became a senator as well.  That's not all she became, of course... she became the leader of her cell in the Alliance against the corrupt Empire. And because she had diplomatic immunity, she was a vital link for getting information to the Rebel cause.  That's what she was doing when her path crossed yours... for her foster parents had always told her to contact me on Tatooine, if her troubles became desperate.\"\n",
      "\"LEIA\"\t\"General Kenobi, years ago you served my father in the Clone Wars.  Now he begs you to help him in his struggle against the Empire.  I regret that I am unable to present my father's request to you in person, but my ship has fallen under attack and I'm afraid my mission to bring you to Alderaan has failed.  I have placed information vital to the survival of the Rebellion into the memory systems of this R2 unit.  My father will know how to retrieve it.  You must see this droid safely delivered to him on Alderaan.  This is our most desperate hour.  Help me, Obi-Wan Kenobi, you're my only hope.\"\n",
      "\"ACKBAR\"\t\"You can see here the Death Star orbiting the forest Moon of Endor. Although the weapon systems on this Death Star are not yet operational, the Death Star does have a strong defense mechanism. It is protected by an energy shield, which is generated from the nearby forest Moon of Endor. The shield must be deactivated if any attack is to be attempted. Once the shield is down, our cruisers will create a perimeter, while the fighters fly into the superstructure and attempt to knock out the main reactor.\"\n",
      "\"LUKE\"\t\"Greetings, Exalted One. Allow me to introduce myself. I am Luke Skywalker, Jedi Knight and friend to Captain Solo. I know that you are powerful, mighty Jabba, and that your anger with Solo must be equally powerful. I seek an audience with Your Greatness to bargain for Solo's life.  With your wisdom, I'm sure that we can work out an arrangement which will be mutually beneficial and enable us to avoid any unpleasant confrontation. As a token of my goodwill, I present to you a gift: these two droids.\"\n",
      "\"MON MOTHMA\"\t\"The data brought to us by the Bothan spies pinpoints the exact location of the Emperor's new battle station. We also know that the weapon systems of this Death Star are not yet operational. With the Imperial Fleet spread throughout the galaxy in a vain effort to engage us, it is relatively unprotected. But most important of all, we've learned that the Emperor himself is personally overseeing the final stages of the construction of this Death Star.\"\n",
      "\"YODA\"\t\"Ready, are you? What know you of ready? For eight hundred years  have I trained Jedi. My own counsel will I keep on who is to be trained! A Jedi must have the deepest commitment, the most serious mind.  This one a long time have I watched. Never his mind on where he was. Hmm? What he was doing. Hmph. Adventure. Heh! Excitement. Heh! A Jedi craves not these things.  You are reckless!\"\n",
      "\"BIGGS\"\t\"I feel for you, Luke, you're going to have to learn what seems to be important or what really is important.  What good is all your uncle's work if it's taken over by the Empire?...  You know they're starting to nationalize commerce in the central systems...it won't be long before your uncle is merely a tenant, slaving for the greater glory of the Empire.\"\n",
      "\"DODONNA\"\t\"The approach will not be easy.  You are required to maneuver straight down this trench and skim the surface to this point.  The target area is only two meters wide.  It's a small thermal exhaust port, right below the main port.  The shaft leads directly to the reactor system.  A precise hit will start a chain reaction which should destroy the station.\"\n",
      "\"JABBA\"\t\"Put your blasters away.  Han, my boy, I'm only doing this because you're the best and I need you.  So, for an extra, say... twenty percent I'll give you a little more time... but this is it.  If you disappoint me again, I'll put a price on your head so large you won't be able to go near a civilized system for the rest of your short life.\"\n",
      "\"TARKIN\"\t\"Not after we demonstrate the power of this station.  In a way, you have determined the choice of the planet that'll be destroyed first.  Since you are reluctant to provide us with the location of the Rebel base, I have chosen to test this station's destructive power... on your home planet of Alderaan.\"\n",
      "\"THREEPIO\"\t\"He says he's the property of Obi-Wan Kenobi, a resident of these parts.  And it's a private message for him.  Quite frankly, sir, I don't know what he's talking about.  Our last master was Captain Antilles, but with what we've been through, this little R2 unit has become a bit eccentric.\"\n",
      "\"VADER\"\t\"There is no escape. Don't make me destroy you. You do not yet  realize your importance. You have only begun to discover you power. Join me and I will complete your training. With our combined strength, we can end this destructive conflict and bring order to the galaxy.\"\n",
      "\"HAN\"\t\"Kid, I've flown from one side of this galaxy to the other.  I've seen a lot of strange stuff, but I've never seen anything to make me believe there's one all-powerful force controlling everything.  There's no mystical energy field that controls my destiny.\"\n",
      "\"MOTTI\"\t\"Don't try to frighten us with your sorcerer's ways, Lord Vader.  Your sad devotion to that ancient religion has not helped you conjure up the stolen data tapes, or given you clairvoyance enough to find the Rebel's hidden fort...\"\n",
      "\"EMPEROR\"\t\"...are walking into a trap. As is your Rebel fleet! It was I who allowed the Alliance to know the location of the shield generator. It is quite safe from your pitiful little band. An entire legion of my best troops awaits them.\"\n",
      "\"OFFICER CASS\"\t\"Our scout ships have reached Dantooine.  They found the remains of a Rebel base, but they estimate that it has been deserted for some time.  They are now conducting an extensive search of the surrounding systems.\"\n",
      "\"LANDO\"\t\"That's always been a danger looming like a shadow over  everything we've built here. But things have developed that will insure security. I've just made a deal that will keep the Empire out of here forever.\"\n",
      "\"VEERS\"\t\"My lord, the fleet has moves out of light-speed. Com-Scan has  detected an energy field protecting an area around the sixth planet of the Hoth system. The field is strong enough to deflect any bombardment.\"\n",
      "\"GREEDO\"\t\"It's too late.  You should have paid him when you had the chance.  Jabba's put a price on your head, so large that every bounty hunter in the galaxy will be looking for you.  I'm lucky I found you first.\"\n",
      "\"OWEN\"\t\"Harvest is when I need you the most.  Only one more season.  This year we'll make enough on the harvest so I'll be able to hire some more hands.  And then you can go to the Academy next year.\"\n",
      "\"TAGGE\"\t\"And what of the Rebellion?  If the Rebels have obtained a complete technical readout of this station, it is possible, however unlikely, that they might find a weakness and exploit it.\"\n",
      "\"SECOND OFFICER\"\t\"Lord Vader, the battle station plans are not aboard this ship!  And no transmissions were made.  An escape pod was jettisoned during the fighting, but no life forms were aboard.\"\n",
      "\"FIXER\"\t\"I keep telling you, the Rebellion is a long way from here.  I doubt if the Empire would even fight to keep this system.  Believe me Luke, this planet is a big hunk of nothing...\"\n",
      "\"PIETT\"\t\"Lord Vader, our ships have completed their scan of the area and  found nothing. If the Millennium Falcon went into light-speed, it'll be on the other side of the galaxy by now.\"\n",
      "\"GENERAL MADINE\"\t\"We have stolen a small Imperial shuttle. Disguised as a cargo ship, and using a secret Imperial code, a strike team will land on the moon and deactivate the shield generator.\"\n",
      "\"OFFICER\"\t\"There's no one on board, sir.  According to the log, the crew abandoned ship right after takeoff.  It must be a decoy, sir.  Several of the escape pods have been jettisoned.\"\n",
      "\"RED LEADER\"\t\"I met your father once when I was just a boy.  He was a great pilot.  You'll do all right.  If you've got half of your father's skill, you'll do better than all right.\"\n",
      "\"COMMANDER\"\t\"This is a Rebel that surrendered to us. Although he denies it, I believe there may be more of them, and I request permission to conduct a further search of the area.\"\n",
      "\"NEEDA\"\t\"...and that, Lord Vader, was the last time they  appeared in any of our scopes. Considering the amount of damage we've sustained, they must have been destroyed.\"\n",
      "\"REBEL CAPTAIN\"\t\"Groups seven and ten will stay behind to fly the  speeders. As soon as each transport is loaded, evacuation control will give clearance for immediate launch.\"\n",
      "\"VOICE\"\t\"We've captured a freighter entering the remains of the Alderaan system.  It's markings match those of a ship that blasted its way out of Mos Eisley.\"\n",
      "\"NINEDENINE\"\t\"You're a feisty little one, but you'll soon learn some respect. I have need for you on the master's Sail Barge. And I think you'll fit in nicely.\"\n",
      "\"DEATH STAR CONTROLLER\"\t\"The security deflector shield will be deactivated when we have confirmation of your code transmission. Stand by... You are clear to proceed.\"\n",
      "\"HAN/PILOT\"\t\"It's over, Commander. The Rebels have been routed. They're fleeing into the woods. We need reinforcements to continue the pursuit.\"\n",
      "\"RIEEKAN\"\t\"Reroute all power to the energy shield. We've got to hold  them till all transports are away. Prepare for ground assault.\"\n",
      "\"DEATH STAR INTERCOM VOICE\"\t\"We are approaching the planet Yavin.  The Rebel base is on a moon on the far side.  We are preparing to orbit the planet.\"\n",
      "\"ZEV\"\t\"This is Rouge Two. this is Rouge Two. Captain  Solo, so you copy? Commander Skywalker, do you copy? This is Rouge Two.\"\n",
      "\"SHUTTLE CAPTAIN\"\t\"Command station, this is ST 321. Code Clearance Blue. We're starting our approach. Deactivate the security shield.\"\n",
      "\"CREATURE\"\t\"Not far. Yoda not far. Patience. Soon you will be with him.   Rootleaf, I cook. Why wish you become Jedi? Hm?\"\n",
      "\"HUMAN\"\t\"Don't insult us.  You just watch yourself.  We're wanted men.  I have the death sentence on twelve systems.\"\n",
      "\"DECK OFFICER\"\t\"Sir, Commander Skywalker hasn't come in through the  south entrance. He might have forgotten to check in.\"\n",
      "\"TROOPER\"\t\"The ship's all yours.  If the scanners pick up anything, report it immediately.  All right, let's go.\"\n",
      "\"CONTROLLER\"\t\"Shuttle Tydirium, deactivation of the shield will commence immediately. Follow your present course.\"\n",
      "\"WEDGE\"\t\"My scope shows the tower, but I can't see the exhaust port!  Are you sure the computer can hit it?\"\n",
      "\"REBEL OFFICER\"\t\"We intercepted no transmissions. Aaah...  This is a consular ship. Were on a diplomatic mission.\"\n",
      "\"ASTRO-OFFICER\"\t\"We count thirty Rebel ships, Lord Vader.  But they're so small they're evading our turbo-lasers!\"\n",
      "\"AUNT BERU\"\t\"Owen, he can't stay here forever.  Most of his friends have gone.  It means so much to him.\"\n",
      "\"WILLARD\"\t\"When we heard about Alderaan, we were afraid that you were... lost along with your father.\"\n",
      "\"MASSASSI INTERCOM VOICE\"\t\"Stand-by alert.  Death Star approaching.  Estimated time to firing range, fifteen minutes.\"\n",
      "\"IMPERIAL OFFICER\"\t\"The final check-out is complete.  All systems are operational.  What course shall we set?\"\n",
      "\"OZZEL\"\t\"My lord, there are so many uncharted settlements. It could be  smugglers, it could be...\"\n",
      "\"DERLIN\"\t\"Your Highness, there's nothing more we can do tonight. The  shield doors must be closed.\"\n",
      "\"CONTROL OFFICER\"\t\"Squad leaders, we've picked up a new group of signals.  Enemy fighters coming your way.\"\n",
      "\"GOLD LEADER\"\t\"Pardon me for asking, sir, but what good are snub fighters going to be against that?\"\n",
      "\"BASE VOICE\"\t\"His computer's off.  Luke, you switched off your targeting computer.  What's wrong?\"\n",
      "\"ANAKIN\"\t\"You already have, Luke. You were right about me. Tell your sister...you were right.\"\n",
      "\"DACK\"\t\"Luke, we've got a malfunction in fire control. I'll have to cut  in the auxiliary.\"\n",
      "\"INTERCOM VOICE\"\t\"Governor Tarkin, we have an emergency alert in detention block AA-twenty-three.\"\n",
      "\"LIEUTENANT\"\t\"Sir, all the patrols are in. There's still no contact from  Skywalker or Solo.\"\n",
      "\"GANTRY OFFICER\"\t\"TX-four-one-two.  Why aren't you at your post?  TX-four-one-two, do you copy? \"\n",
      "\"CAPTAIN\"\t\"Hold your fire.  There are no life forms.  It must have been short-circuited.\"\n",
      "\"MAN\"\t\"All flight troops, man your stations.  All flight troops, man your stations.\"\n",
      "\"JERJERROD\"\t\"Lord Vader, this is an unexpected pleasure.  We're honored by your presence.\"\n",
      "\"BERU\"\t\"Luke, tell Owen that if he gets a translator to be sure it speaks Bocce.\"\n",
      "\"GOLD FIVE\"\t\"I'd say about twenty guns.  Some on the surface, some on the towers.\"\n",
      "\"BARTENDER\"\t\"Your droids. They'll have to wait outside.  We don't want them here.\"\n",
      "\"VOICE OVER DEATH STAR INTERCOM\"\t\"Clear Bay twenty-three-seven.  We are opening the magnetic field.\"\n",
      "\"CHIEF\"\t\"This R2 unit of your seems a bit beat up.  Do you want a new one?\"\n",
      "\"SECOND CONTROLLER\"\t\"Sir, we have a priority signal from the Star  Destroyer Avenger.\"\n",
      "\"RED TEN\"\t\"There's a heavy fire zone on this side. Red Five, where are you?\"\n",
      "\"MEDICAL DROID\"\t\"Sir, it will take quite awhile to evacuate the T-forty-  sevens.\"\n",
      "\"GUARD\"\t\"Halt! The Emperor does not wish to be disturbed at the moment.\"\n",
      "\"FIRST TROOPER\"\t\"Someone was in the pod.  The tracks go off in this direction. \"\n",
      "\"ASSISTANT OFFICER\"\t\"I'll cover sector twelve. Have com-control set  screen alpha.\"\n",
      "\"TRACKING OFFICER\"\t\"Captain Needa, the ship no longer appears on our  scopes.\"\n",
      "\"SENIOR CONTROLLER\"\t\"No. Wait -- there's something very weak coming  through.\"\n",
      "\"COMMUNICATIONS OFFICER\"\t\"Captain, Lord Vader demands an update on the  pursuit.\"\n",
      "\"BOUSHH\"\t\"Just relax for a moment. You're free of the carbonite.\"\n",
      "\"BOBA FETT\"\t\"What if he doesn't survive? He's worth a lot to me.\"\n",
      "\"ANNOUNCER\"\t\"Headquarters personnel, report to command  center.\"\n",
      "\"CONTROL ROOM COMMANDER\"\t\"Send three squads to help. Open the back door.\"\n",
      "\"PILOT VOICE\"\t\"Parts and technical crew for the forest moon.\"\n",
      "\"SCOUT #1\"\t\"Go get your ride and take her back to base.\"\n",
      "\"IMPERIAL SOLDIER\"\t\"Lord Vader, ship approaching. X-wing class.\"\n",
      "\"STORMTROOPER\"\t\"All right, move it! I said move it! Go on!\"\n",
      "\"RED THREE\"\t\"Three of them coming in, twenty degrees!\"\n",
      "\"BIB\"\t\"Nee Jabba no badda. Me chaade su goodie.\"\n",
      "\"HOBBIE\"\t\"Two fighters against a Star Destroyer?\"\n",
      "\"CAMIE\"\t\"It was just Wormie on another rampage.\"\n",
      "\"OOLA\"\t\"Na Chuba negatorie Na! Na! Natoota...\"\n",
      "\"GOLD TWO\"\t\"Computer's locked.  Getting a signal.\"\n",
      "\"TECHNICIAN\"\t\"We'll get to work on him right away.\"\n",
      "\"HEAD CONTROLLER\"\t\"K-one-zero...all troops disengage.\"\n",
      "\"TRENCH OFFICER\"\t\"We have spotted Imperial walkers!\"\n",
      "\"WOMAN\"\t\"I've told you kids to slow down!\"\n",
      "\"WOMAN CONTROLLER\"\t\"Stand by, ion control....Fire!\"\n",
      "\"PILOT\"\t\"One-seven, decimal two-eight.\"\n",
      "\"FIRST OFFICER\"\t\"Follow me!  You stand guard.\"\n",
      "\"SCOUT\"\t\"Look! Over there! Stop him!\"\n",
      "\"BUNKER COMMANDER\"\t\"Bring those two down here!\"\n",
      "\"SECOND TROOPER\"\t\"Maybe it's another drill.\"\n",
      "\"SCOUT #l\"\t\"Freeze!  Come on, get up!\"\n",
      "\"REBEL PILOT\"\t\"There's too many of them!\"\n",
      "\"JANSON\"\t\"Coming around. Once more.\"\n",
      "\"GREEN LEADER\"\t\"Green Leader standing by.\"\n",
      "\"GRAY LEADER\"\t\"Gray Leader standing by.\"\n",
      "\"RED ELEVEN\"\t\"Red Eleven standing by.\"\n",
      "\"CHIEF PILOT\"\t\"There goes another one.\"\n",
      "\"RED SEVEN\"\t\"Red Seven standing by.\"\n",
      "\"DEAK\"\t\"Not again!  Forget it.\"\n",
      "\"RED NINE\"\t\"Red Nine standing by.\"\n",
      "\"PILOT #2\"\t\"Get him off of there!\"\n",
      "\"STRANGE VOICE\"\t\"Tee chuta hhat yudd!\"\n",
      "\"PORKINS\"\t\"Red Six standing by.\"\n",
      "\"NAVIGATOR\"\t\"Pressure's steady.\"\n",
      "\"TROOPER VOICE\"\t\"Open up in there!\"\n",
      "\"LURE\"\t\"But you'll die.\"\n",
      "\"PILOTS\"\t\"Right. Okay.\"\n",
      "\"REBEL FIGHTER\"\t\"Right, sir.\"\n",
      "\"WINGMAN\"\t\"Look out!\"\n",
      "\"SECOND THREEPIO\"\t\"E chu ta!\"\n",
      "\"SECOND COMMANDER\"\t\"Yes, sir.\"\n",
      "\"SCOUT #2\"\t\"Yes, sir.\"\n",
      "\"OPERATOR\"\t\"Yes, sir.\"\n",
      "\"FIRST CONTROLLER\"\t\"Yes, sir.\"\n",
      "\"Y-WING PILOT\"\t\"I'm hit!\"\n",
      "\"RED TWO\"\t\"Got it!\"\n",
      "\"WALKER PILOT #1\"\t\"Look!\"\n",
      "\"HAN and LUKE\"\t\"Leia!\"\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat /homework_2_2/SW_EpisodeIVVVI_longest/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772daa7e-ffd4-41e3-8617-b5534a1a60b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
